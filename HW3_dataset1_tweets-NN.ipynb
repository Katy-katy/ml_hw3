{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv(\"tweets_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "\n",
    "X = all_data.clean_text\n",
    "y = all_data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_row = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=1000) # limit number of features to avoid overfitting\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6090, 1000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.toarray()\n",
    "X_test = X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer_1:  2 layer_2:  2  accuracy:  0.7438423645320197\n",
      " layer_1:  2 layer_2:  3  accuracy:  0.7561576354679803\n",
      " layer_1:  2 layer_2:  4  accuracy:  0.7536945812807881\n",
      " layer_1:  2 layer_2:  5  accuracy:  0.5665024630541872\n",
      " layer_1:  3 layer_2:  2  accuracy:  0.7495894909688013\n",
      " layer_1:  3 layer_2:  3  accuracy:  0.7504105090311987\n",
      " layer_1:  3 layer_2:  4  accuracy:  0.7520525451559934\n",
      " layer_1:  3 layer_2:  5  accuracy:  0.7504105090311987\n",
      " layer_1:  4 layer_2:  2  accuracy:  0.7413793103448276\n",
      " layer_1:  4 layer_2:  3  accuracy:  0.7610837438423645\n",
      " layer_1:  4 layer_2:  4  accuracy:  0.7282430213464697\n",
      " layer_1:  4 layer_2:  5  accuracy:  0.7487684729064039\n",
      " layer_1:  5 layer_2:  2  accuracy:  0.7536945812807881\n",
      " layer_1:  5 layer_2:  3  accuracy:  0.5665024630541872\n",
      " layer_1:  5 layer_2:  4  accuracy:  0.7553366174055829\n",
      " layer_1:  5 layer_2:  5  accuracy:  0.7389162561576355\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "layer_1 = [2, 3, 4, 5]\n",
    "layer_2 = [2, 3, 4, 5]\n",
    "\n",
    "for i in layer_1:\n",
    "    for j in layer_2:\n",
    "        clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(i, j), random_state=1) \n",
    "        scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "        print(\" layer_1: \", i, \"layer_2: \", j,  \" accuracy: \", np.median(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  1.2049107551574707\n",
      "Training accuracy:  0.8249589490968802\n",
      "prediction time:  0.0017518997192382812\n",
      "Testing accuracy:  0.783322390019698\n"
     ]
    }
   ],
   "source": [
    "# predict on the test data using the best parameters\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(2,3), random_state=1) \n",
    "now0 = time()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"training time: \", time()-now0)\n",
    "print(\"Training accuracy: \", accuracy_score(y_train, clf.predict(X_train)))\n",
    "now = time()\n",
    "pr = clf.predict(X_test)\n",
    "print(\"prediction time: \", time()-now)\n",
    "print(\"Testing accuracy: \", accuracy_score(y_test, pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6090, 1000)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-means clustering and Expectation Maximization on row data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import IncrementalPCA \n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn import metrics\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.079972743988037"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterer = KMeans(n_clusters=150, random_state=10)\n",
    "now = time()\n",
    "cluster_labels = clusterer.fit_predict(X_train)\n",
    "time() - now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01359105110168457"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = time()\n",
    "cluster_labels_test = clusterer.predict(X_test)\n",
    "time() - now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 27, 92, ..., 34, 75, 34], dtype=int32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(cluster_labels.reshape(-1, 1))\n",
    "cl_l_onhot = enc.transform(cluster_labels.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_l_test_onhot = enc.transform(cluster_labels_test.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer_1:  2 layer_2:  2  accuracy:  0.5665024630541872\n",
      " layer_1:  2 layer_2:  3  accuracy:  0.7151067323481116\n",
      " layer_1:  2 layer_2:  4  accuracy:  0.7151067323481116\n",
      " layer_1:  2 layer_2:  5  accuracy:  0.7151067323481116\n",
      " layer_1:  3 layer_2:  2  accuracy:  0.5665024630541872\n",
      " layer_1:  3 layer_2:  3  accuracy:  0.7142857142857143\n",
      " layer_1:  3 layer_2:  4  accuracy:  0.7167487684729064\n",
      " layer_1:  3 layer_2:  5  accuracy:  0.7151067323481116\n",
      " layer_1:  4 layer_2:  2  accuracy:  0.7167487684729064\n",
      " layer_1:  4 layer_2:  3  accuracy:  0.7151067323481116\n",
      " layer_1:  4 layer_2:  4  accuracy:  0.7167487684729064\n",
      " layer_1:  4 layer_2:  5  accuracy:  0.7167487684729064\n",
      " layer_1:  5 layer_2:  2  accuracy:  0.5665024630541872\n",
      " layer_1:  5 layer_2:  3  accuracy:  0.7151067323481116\n",
      " layer_1:  5 layer_2:  4  accuracy:  0.7151067323481116\n",
      " layer_1:  5 layer_2:  5  accuracy:  0.7151067323481116\n"
     ]
    }
   ],
   "source": [
    "layer_1 = [2, 3, 4, 5]\n",
    "layer_2 = [2, 3, 4, 5]\n",
    "\n",
    "for i in layer_1:\n",
    "    for j in layer_2:\n",
    "        clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(i, j), random_state=1) \n",
    "        scores = cross_val_score(clf, cl_l_onhot, y_train, cv=5, scoring='accuracy')\n",
    "        print(\" layer_1: \", i, \"layer_2: \", j,  \" accuracy: \", np.median(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  0.14440107345581055\n",
      "Training accuracy:  0.7307060755336617\n",
      "prediction time:  0.0005950927734375\n",
      "Testing accuracy:  0.7150361129349967\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(2,3), random_state=1) \n",
    "now1 = time()\n",
    "clf.fit(cl_l_onhot, y_train)\n",
    "print(\"training time: \", time()-now1)\n",
    "print(\"Training accuracy: \", accuracy_score(y_train, clf.predict(cl_l_onhot)))\n",
    "now2 = time()\n",
    "pr = clf.predict(cl_l_test_onhot)\n",
    "print(\"prediction time: \", time()-now2)\n",
    "print(\"Testing accuracy: \", accuracy_score(y_test, pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.593796968460083"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterer = GaussianMixture(n_components=147, covariance_type='spherical', random_state=10)\n",
    "now = time()\n",
    "cluster_labels = clusterer.fit_predict(X_train)\n",
    "time() - now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017373085021972656"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = time()\n",
    "cluster_labels_test = clusterer.predict(X_test)\n",
    "time() - now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(cluster_labels.reshape(-1, 1))\n",
    "cl_l_onhot = enc.transform(cluster_labels.reshape(-1, 1)).toarray()\n",
    "cl_l_test_onhot = enc.transform(cluster_labels_test.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer_1:  2 layer_2:  2  accuracy:  0.6921182266009852\n",
      " layer_1:  2 layer_2:  3  accuracy:  0.6904761904761905\n",
      " layer_1:  2 layer_2:  4  accuracy:  0.5665024630541872\n",
      " layer_1:  2 layer_2:  5  accuracy:  0.6904761904761905\n",
      " layer_1:  3 layer_2:  2  accuracy:  0.5665024630541872\n",
      " layer_1:  3 layer_2:  3  accuracy:  0.6904761904761905\n",
      " layer_1:  3 layer_2:  4  accuracy:  0.6904761904761905\n",
      " layer_1:  3 layer_2:  5  accuracy:  0.6904761904761905\n",
      " layer_1:  4 layer_2:  2  accuracy:  0.5665024630541872\n",
      " layer_1:  4 layer_2:  3  accuracy:  0.6912972085385879\n",
      " layer_1:  4 layer_2:  4  accuracy:  0.6929392446633826\n",
      " layer_1:  4 layer_2:  5  accuracy:  0.6912972085385879\n",
      " layer_1:  5 layer_2:  2  accuracy:  0.6912972085385879\n",
      " layer_1:  5 layer_2:  3  accuracy:  0.6912972085385879\n",
      " layer_1:  5 layer_2:  4  accuracy:  0.6921182266009852\n",
      " layer_1:  5 layer_2:  5  accuracy:  0.6904761904761905\n"
     ]
    }
   ],
   "source": [
    "layer_1 = [2, 3, 4, 5]\n",
    "layer_2 = [2, 3, 4, 5]\n",
    "\n",
    "for i in layer_1:\n",
    "    for j in layer_2:\n",
    "        clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(i, j), random_state=1) \n",
    "        scores = cross_val_score(clf, cl_l_onhot, y_train, cv=5, scoring='accuracy')\n",
    "        print(\" layer_1: \", i, \"layer_2: \", j,  \" accuracy: \", np.median(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  0.31490397453308105\n",
      "Training accuracy:  0.7018062397372742\n",
      "prediction time:  0.0006358623504638672\n",
      "Testing accuracy:  0.6736703873933026\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(2,3), random_state=1) \n",
    "now1 = time()\n",
    "clf.fit(cl_l_onhot, y_train)\n",
    "print(\"training time: \", time()-now1)\n",
    "print(\"Training accuracy: \", accuracy_score(y_train, clf.predict(cl_l_onhot)))\n",
    "now2 = time()\n",
    "pr = clf.predict(cl_l_test_onhot)\n",
    "print(\"prediction time: \", time()-now2)\n",
    "print(\"Testing accuracy: \", accuracy_score(y_test, pr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=0,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(random_state=0)\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5621092319488525"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = time()\n",
    "pca = PCA(random_state=0)\n",
    "pca.fit(X_train)\n",
    "transformed_data = pca.transform(X_train)[:, :600]\n",
    "time() - now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.050328969955444336"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = time()\n",
    "transformed_data_test = pca.transform(X_test)[:, :600]\n",
    "time() - now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer_1:  2 layer_2:  2  accuracy:  0.7602627257799671\n",
      " layer_1:  2 layer_2:  3  accuracy:  0.7430213464696224\n",
      " layer_1:  2 layer_2:  4  accuracy:  0.7635467980295566\n",
      " layer_1:  2 layer_2:  5  accuracy:  0.7594417077175698\n",
      " layer_1:  3 layer_2:  2  accuracy:  0.7487684729064039\n",
      " layer_1:  3 layer_2:  3  accuracy:  0.7446633825944171\n",
      " layer_1:  3 layer_2:  4  accuracy:  0.7405582922824302\n",
      " layer_1:  3 layer_2:  5  accuracy:  0.7487684729064039\n",
      " layer_1:  4 layer_2:  2  accuracy:  0.7479474548440066\n",
      " layer_1:  4 layer_2:  3  accuracy:  0.7668308702791461\n",
      " layer_1:  4 layer_2:  4  accuracy:  0.5665024630541872\n",
      " layer_1:  4 layer_2:  5  accuracy:  0.7307060755336617\n",
      " layer_1:  5 layer_2:  2  accuracy:  0.5665024630541872\n",
      " layer_1:  5 layer_2:  3  accuracy:  0.7684729064039408\n",
      " layer_1:  5 layer_2:  4  accuracy:  0.7438423645320197\n",
      " layer_1:  5 layer_2:  5  accuracy:  0.7569786535303776\n"
     ]
    }
   ],
   "source": [
    "layer_1 = [2, 3, 4, 5]\n",
    "layer_2 = [2, 3, 4, 5]\n",
    "\n",
    "for i in layer_1:\n",
    "    for j in layer_2:\n",
    "        clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(i, j), random_state=1) \n",
    "        scores = cross_val_score(clf, transformed_data, y_train, cv=5, scoring='accuracy')\n",
    "        print(\" layer_1: \", i, \"layer_2: \", j,  \" accuracy: \", np.median(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  5.614315748214722\n",
      "Training accuracy:  0.870607553366174\n",
      "prediction time:  0.0056989192962646484\n",
      "Testing accuracy:  0.7636244254760342\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(2,3), random_state=1) \n",
    "now1 = time()\n",
    "clf.fit(transformed_data, y_train)\n",
    "print(\"training time: \", time()-now1)\n",
    "print(\"Training accuracy: \", accuracy_score(y_train, clf.predict(transformed_data)))\n",
    "now2 = time()\n",
    "pr = clf.predict(transformed_data_test)\n",
    "print(\"prediction time: \", time()-now2)\n",
    "print(\"Testing accuracy: \", accuracy_score(y_test, pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  5.832362651824951\n",
      "Training accuracy:  0.8303776683087027\n",
      "prediction time:  0.003262042999267578\n",
      "Testing accuracy:  0.7760998030203545\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(2,2), random_state=1) \n",
    "now1 = time()\n",
    "clf.fit(transformed_data, y_train)\n",
    "print(\"training time: \", time()-now1)\n",
    "print(\"Training accuracy: \", accuracy_score(y_train, clf.predict(transformed_data)))\n",
    "now2 = time()\n",
    "pr = clf.predict(transformed_data_test)\n",
    "print(\"prediction time: \", time()-now2)\n",
    "print(\"Testing accuracy: \", accuracy_score(y_test, pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.151318073272705"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterer = KMeans(n_clusters=140, random_state=10)\n",
    "now = time()\n",
    "cluster_labels = clusterer.fit_predict(transformed_data)\n",
    "time() - now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014474868774414062"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = time()\n",
    "cluster_labels_test = clusterer.predict(transformed_data_test)\n",
    "time() - now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(cluster_labels.reshape(-1, 1))\n",
    "cl_l_onhot = enc.transform(cluster_labels.reshape(-1, 1)).toarray()\n",
    "cl_l_test_onhot = enc.transform(cluster_labels_test.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer_1:  2 layer_2:  2  accuracy:  0.7093596059113301\n",
      " layer_1:  2 layer_2:  3  accuracy:  0.7192118226600985\n",
      " layer_1:  2 layer_2:  4  accuracy:  0.7167487684729064\n",
      " layer_1:  2 layer_2:  5  accuracy:  0.7192118226600985\n",
      " layer_1:  3 layer_2:  2  accuracy:  0.7175697865353038\n",
      " layer_1:  3 layer_2:  3  accuracy:  0.7142857142857143\n",
      " layer_1:  3 layer_2:  4  accuracy:  0.7126436781609196\n",
      " layer_1:  3 layer_2:  5  accuracy:  0.7118226600985221\n",
      " layer_1:  4 layer_2:  2  accuracy:  0.7126436781609196\n",
      " layer_1:  4 layer_2:  3  accuracy:  0.7142857142857143\n",
      " layer_1:  4 layer_2:  4  accuracy:  0.7151067323481116\n",
      " layer_1:  4 layer_2:  5  accuracy:  0.7192118226600985\n",
      " layer_1:  5 layer_2:  2  accuracy:  0.7175697865353038\n",
      " layer_1:  5 layer_2:  3  accuracy:  0.7167487684729064\n",
      " layer_1:  5 layer_2:  4  accuracy:  0.7118226600985221\n",
      " layer_1:  5 layer_2:  5  accuracy:  0.7200328407224958\n"
     ]
    }
   ],
   "source": [
    "layer_1 = [2, 3, 4, 5]\n",
    "layer_2 = [2, 3, 4, 5]\n",
    "\n",
    "for i in layer_1:\n",
    "    for j in layer_2:\n",
    "        clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(i, j), random_state=1) \n",
    "        scores = cross_val_score(clf, cl_l_onhot, y_train, cv=5, scoring='accuracy')\n",
    "        print(\" layer_1: \", i, \"layer_2: \", j,  \" accuracy: \", np.median(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  0.23170089721679688\n",
      "Training accuracy:  0.725615763546798\n",
      "prediction time:  0.0005669593811035156\n",
      "Testing accuracy:  0.716349310571241\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(2,3), random_state=1) \n",
    "now1 = time()\n",
    "clf.fit(cl_l_onhot, y_train)\n",
    "print(\"training time: \", time()-now1)\n",
    "print(\"Training accuracy: \", accuracy_score(y_train, clf.predict(cl_l_onhot)))\n",
    "now2 = time()\n",
    "pr = clf.predict(cl_l_test_onhot)\n",
    "print(\"prediction time: \", time()-now2)\n",
    "print(\"Testing accuracy: \", accuracy_score(y_test, pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.8777830600738525"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterer = GaussianMixture(n_components=160, covariance_type='spherical', random_state=10)\n",
    "now = time()\n",
    "cluster_labels = clusterer.fit_predict(transformed_data)\n",
    "time() - now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014285802841186523"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = time()\n",
    "cluster_labels_test = clusterer.predict(transformed_data_test)\n",
    "time() - now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(cluster_labels.reshape(-1, 1))\n",
    "cl_l_onhot = enc.transform(cluster_labels.reshape(-1, 1)).toarray()\n",
    "cl_l_test_onhot = enc.transform(cluster_labels_test.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer_1:  2 layer_2:  2  accuracy:  0.6970443349753694\n",
      " layer_1:  2 layer_2:  3  accuracy:  0.7019704433497537\n",
      " layer_1:  2 layer_2:  4  accuracy:  0.7060755336617406\n",
      " layer_1:  2 layer_2:  5  accuracy:  0.7060755336617406\n",
      " layer_1:  3 layer_2:  2  accuracy:  0.7060755336617406\n",
      " layer_1:  3 layer_2:  3  accuracy:  0.5665024630541872\n",
      " layer_1:  3 layer_2:  4  accuracy:  0.6995073891625616\n",
      " layer_1:  3 layer_2:  5  accuracy:  0.7036124794745484\n",
      " layer_1:  4 layer_2:  2  accuracy:  0.5665024630541872\n",
      " layer_1:  4 layer_2:  3  accuracy:  0.6995073891625616\n",
      " layer_1:  4 layer_2:  4  accuracy:  0.7019704433497537\n",
      " layer_1:  4 layer_2:  5  accuracy:  0.7077175697865353\n",
      " layer_1:  5 layer_2:  2  accuracy:  0.6962233169129721\n",
      " layer_1:  5 layer_2:  3  accuracy:  0.7060755336617406\n",
      " layer_1:  5 layer_2:  4  accuracy:  0.5665024630541872\n",
      " layer_1:  5 layer_2:  5  accuracy:  0.7060755336617406\n"
     ]
    }
   ],
   "source": [
    "layer_1 = [2, 3, 4, 5]\n",
    "layer_2 = [2, 3, 4, 5]\n",
    "\n",
    "for i in layer_1:\n",
    "    for j in layer_2:\n",
    "        clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(i, j), random_state=1) \n",
    "        scores = cross_val_score(clf, cl_l_onhot, y_train, cv=5, scoring='accuracy')\n",
    "        print(\" layer_1: \", i, \"layer_2: \", j,  \" accuracy: \", np.median(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  0.2621641159057617\n",
      "Training accuracy:  0.7229885057471265\n",
      "prediction time:  0.0006170272827148438\n",
      "Testing accuracy:  0.7019041365725541\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(2,3), random_state=1) \n",
    "now1 = time()\n",
    "clf.fit(cl_l_onhot, y_train)\n",
    "print(\"training time: \", time()-now1)\n",
    "print(\"Training accuracy: \", accuracy_score(y_train, clf.predict(cl_l_onhot)))\n",
    "now2 = time()\n",
    "pr = clf.predict(cl_l_test_onhot)\n",
    "print(\"prediction time: \", time()-now2)\n",
    "print(\"Testing accuracy: \", accuracy_score(y_test, pr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.609138011932373\n"
     ]
    }
   ],
   "source": [
    "ica = FastICA(random_state=0,n_components=7,  tol=1.0, max_iter=10000)\n",
    "now = time()\n",
    "ica.fit(X_train)\n",
    "td = ica.transform(X_train)\n",
    "print(time()-now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004333972930908203\n"
     ]
    }
   ],
   "source": [
    "now = time()\n",
    "td_test = ica.transform(X_test)\n",
    "print(time()-now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  0.010246992111206055\n",
      "Training accuracy:  0.5665024630541872\n",
      "prediction time:  0.0008528232574462891\n",
      "Testing accuracy:  0.5856861457649376\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(2,3), random_state=1) \n",
    "now1 = time()\n",
    "clf.fit(td, y_train)\n",
    "print(\"training time: \", time()-now1)\n",
    "print(\"Training accuracy: \", accuracy_score(y_train, clf.predict(td)))\n",
    "now2 = time()\n",
    "pr = clf.predict(td_test)\n",
    "print(\"prediction time: \", time()-now2)\n",
    "print(\"Testing accuracy: \", accuracy_score(y_test, pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer_1:  2 layer_2:  2  accuracy:  0.6379310344827587\n",
      " layer_1:  2 layer_2:  3  accuracy:  0.5665024630541872\n",
      " layer_1:  2 layer_2:  4  accuracy:  0.6535303776683087\n",
      " layer_1:  2 layer_2:  5  accuracy:  0.6395730706075534\n",
      " layer_1:  3 layer_2:  2  accuracy:  0.6223316912972086\n",
      " layer_1:  3 layer_2:  3  accuracy:  0.5665024630541872\n",
      " layer_1:  3 layer_2:  4  accuracy:  0.6379310344827587\n",
      " layer_1:  3 layer_2:  5  accuracy:  0.638752052545156\n",
      " layer_1:  4 layer_2:  2  accuracy:  0.6535303776683087\n",
      " layer_1:  4 layer_2:  3  accuracy:  0.6543513957307061\n",
      " layer_1:  4 layer_2:  4  accuracy:  0.6379310344827587\n",
      " layer_1:  4 layer_2:  5  accuracy:  0.6568144499178982\n",
      " layer_1:  5 layer_2:  2  accuracy:  0.6444991789819376\n",
      " layer_1:  5 layer_2:  3  accuracy:  0.5665024630541872\n",
      " layer_1:  5 layer_2:  4  accuracy:  0.6559934318555009\n",
      " layer_1:  5 layer_2:  5  accuracy:  0.6371100164203612\n"
     ]
    }
   ],
   "source": [
    "layer_1 = [2, 3, 4, 5]\n",
    "layer_2 = [2, 3, 4, 5]\n",
    "\n",
    "for i in layer_1:\n",
    "    for j in layer_2:\n",
    "        clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(i, j), random_state=1) \n",
    "        scores = cross_val_score(clf, td, y_train, cv=5, scoring='accuracy')\n",
    "        print(\" layer_1: \", i, \"layer_2: \", j,  \" accuracy: \", np.median(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  0.16428184509277344\n",
      "Training accuracy:  0.6482758620689655\n",
      "prediction time:  0.0006070137023925781\n",
      "Testing accuracy:  0.6506894287590282\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(2,4), random_state=1) \n",
    "now1 = time()\n",
    "clf.fit(td, y_train)\n",
    "print(\"training time: \", time()-now1)\n",
    "print(\"Training accuracy: \", accuracy_score(y_train, clf.predict(td)))\n",
    "now2 = time()\n",
    "pr = clf.predict(td_test)\n",
    "print(\"prediction time: \", time()-now2)\n",
    "print(\"Testing accuracy: \", accuracy_score(y_test, pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0600428581237793"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterer = KMeans(n_clusters=3, random_state=10)\n",
    "now = time()\n",
    "cluster_labels = clusterer.fit_predict(td)\n",
    "time() - now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012378692626953125"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = time()\n",
    "cluster_labels_test = clusterer.predict(td_test)\n",
    "time() - now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(cluster_labels.reshape(-1, 1))\n",
    "cl_l_onhot = enc.transform(cluster_labels.reshape(-1, 1)).toarray()\n",
    "cl_l_test_onhot = enc.transform(cluster_labels_test.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer_1:  2 layer_2:  2  accuracy:  0.5665024630541872\n",
      " layer_1:  2 layer_2:  3  accuracy:  0.5665024630541872\n",
      " layer_1:  2 layer_2:  4  accuracy:  0.5665024630541872\n",
      " layer_1:  2 layer_2:  5  accuracy:  0.5665024630541872\n",
      " layer_1:  2 layer_2:  10  accuracy:  0.5665024630541872\n",
      " layer_1:  2 layer_2:  50  accuracy:  0.5665024630541872\n",
      " layer_1:  3 layer_2:  2  accuracy:  0.5665024630541872\n",
      " layer_1:  3 layer_2:  3  accuracy:  0.5665024630541872\n",
      " layer_1:  3 layer_2:  4  accuracy:  0.5665024630541872\n",
      " layer_1:  3 layer_2:  5  accuracy:  0.5665024630541872\n",
      " layer_1:  3 layer_2:  10  accuracy:  0.5665024630541872\n",
      " layer_1:  3 layer_2:  50  accuracy:  0.5665024630541872\n",
      " layer_1:  4 layer_2:  2  accuracy:  0.5665024630541872\n",
      " layer_1:  4 layer_2:  3  accuracy:  0.5665024630541872\n",
      " layer_1:  4 layer_2:  4  accuracy:  0.5665024630541872\n",
      " layer_1:  4 layer_2:  5  accuracy:  0.5665024630541872\n",
      " layer_1:  4 layer_2:  10  accuracy:  0.5665024630541872\n",
      " layer_1:  4 layer_2:  50  accuracy:  0.5665024630541872\n",
      " layer_1:  5 layer_2:  2  accuracy:  0.5665024630541872\n",
      " layer_1:  5 layer_2:  3  accuracy:  0.5665024630541872\n",
      " layer_1:  5 layer_2:  4  accuracy:  0.5665024630541872\n",
      " layer_1:  5 layer_2:  5  accuracy:  0.5665024630541872\n",
      " layer_1:  5 layer_2:  10  accuracy:  0.5665024630541872\n",
      " layer_1:  5 layer_2:  50  accuracy:  0.5665024630541872\n",
      " layer_1:  10 layer_2:  2  accuracy:  0.5665024630541872\n",
      " layer_1:  10 layer_2:  3  accuracy:  0.5665024630541872\n",
      " layer_1:  10 layer_2:  4  accuracy:  0.5665024630541872\n",
      " layer_1:  10 layer_2:  5  accuracy:  0.5665024630541872\n",
      " layer_1:  10 layer_2:  10  accuracy:  0.5665024630541872\n",
      " layer_1:  10 layer_2:  50  accuracy:  0.5665024630541872\n",
      " layer_1:  50 layer_2:  2  accuracy:  0.5665024630541872\n",
      " layer_1:  50 layer_2:  3  accuracy:  0.5665024630541872\n",
      " layer_1:  50 layer_2:  4  accuracy:  0.5665024630541872\n",
      " layer_1:  50 layer_2:  5  accuracy:  0.5665024630541872\n",
      " layer_1:  50 layer_2:  10  accuracy:  0.5665024630541872\n",
      " layer_1:  50 layer_2:  50  accuracy:  0.5665024630541872\n"
     ]
    }
   ],
   "source": [
    "layer_1 = [2, 3, 4, 5, 10, 50]\n",
    "layer_2 = [2, 3, 4, 5, 10, 50]\n",
    "\n",
    "for i in layer_1:\n",
    "    for j in layer_2:\n",
    "        clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(i, j), random_state=1) \n",
    "        scores = cross_val_score(clf, cl_l_onhot, y_train, cv=5, scoring='accuracy')\n",
    "        print(\" layer_1: \", i, \"layer_2: \", j,  \" accuracy: \", np.median(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09441614151000977"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterer = GaussianMixture(n_components=20, covariance_type='spherical', random_state=10)\n",
    "now = time()\n",
    "cluster_labels = clusterer.fit_predict(td)\n",
    "time() - now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0013310909271240234"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = time()\n",
    "cluster_labels_test = clusterer.predict(td_test)\n",
    "time() - now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(cluster_labels.reshape(-1, 1))\n",
    "cl_l_onhot = enc.transform(cluster_labels.reshape(-1, 1)).toarray()\n",
    "cl_l_test_onhot = enc.transform(cluster_labels_test.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer_1:  2 layer_2:  2  accuracy:  0.5665024630541872\n",
      " layer_1:  2 layer_2:  3  accuracy:  0.5665024630541872\n",
      " layer_1:  2 layer_2:  4  accuracy:  0.6428571428571429\n",
      " layer_1:  2 layer_2:  5  accuracy:  0.645320197044335\n",
      " layer_1:  2 layer_2:  10  accuracy:  0.645320197044335\n",
      " layer_1:  2 layer_2:  50  accuracy:  0.6428571428571429\n",
      " layer_1:  3 layer_2:  2  accuracy:  0.6428571428571429\n",
      " layer_1:  3 layer_2:  3  accuracy:  0.6428571428571429\n",
      " layer_1:  3 layer_2:  4  accuracy:  0.59688013136289\n",
      " layer_1:  3 layer_2:  5  accuracy:  0.645320197044335\n",
      " layer_1:  3 layer_2:  10  accuracy:  0.645320197044335\n",
      " layer_1:  3 layer_2:  50  accuracy:  0.6042692939244664\n",
      " layer_1:  4 layer_2:  2  accuracy:  0.645320197044335\n",
      " layer_1:  4 layer_2:  3  accuracy:  0.645320197044335\n",
      " layer_1:  4 layer_2:  4  accuracy:  0.645320197044335\n",
      " layer_1:  4 layer_2:  5  accuracy:  0.645320197044335\n",
      " layer_1:  4 layer_2:  10  accuracy:  0.6428571428571429\n",
      " layer_1:  4 layer_2:  50  accuracy:  0.645320197044335\n",
      " layer_1:  5 layer_2:  2  accuracy:  0.645320197044335\n",
      " layer_1:  5 layer_2:  3  accuracy:  0.6428571428571429\n",
      " layer_1:  5 layer_2:  4  accuracy:  0.645320197044335\n",
      " layer_1:  5 layer_2:  5  accuracy:  0.6428571428571429\n",
      " layer_1:  5 layer_2:  10  accuracy:  0.6428571428571429\n",
      " layer_1:  5 layer_2:  50  accuracy:  0.6428571428571429\n",
      " layer_1:  10 layer_2:  2  accuracy:  0.6428571428571429\n",
      " layer_1:  10 layer_2:  3  accuracy:  0.6379310344827587\n",
      " layer_1:  10 layer_2:  4  accuracy:  0.6428571428571429\n",
      " layer_1:  10 layer_2:  5  accuracy:  0.645320197044335\n",
      " layer_1:  10 layer_2:  10  accuracy:  0.645320197044335\n",
      " layer_1:  10 layer_2:  50  accuracy:  0.6428571428571429\n",
      " layer_1:  50 layer_2:  2  accuracy:  0.645320197044335\n",
      " layer_1:  50 layer_2:  3  accuracy:  0.6428571428571429\n",
      " layer_1:  50 layer_2:  4  accuracy:  0.6428571428571429\n",
      " layer_1:  50 layer_2:  5  accuracy:  0.645320197044335\n",
      " layer_1:  50 layer_2:  10  accuracy:  0.645320197044335\n",
      " layer_1:  50 layer_2:  50  accuracy:  0.6428571428571429\n"
     ]
    }
   ],
   "source": [
    "layer_1 = [2, 3, 4, 5, 10, 50]\n",
    "layer_2 = [2, 3, 4, 5, 10, 50]\n",
    "\n",
    "for i in layer_1:\n",
    "    for j in layer_2:\n",
    "        clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(i, j), random_state=1) \n",
    "        scores = cross_val_score(clf, cl_l_onhot, y_train, cv=5, scoring='accuracy')\n",
    "        print(\" layer_1: \", i, \"layer_2: \", j,  \" accuracy: \", np.median(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  0.1144707202911377\n",
      "Training accuracy:  0.6435139573070607\n",
      "prediction time:  0.0005688667297363281\n",
      "Testing accuracy:  0.6362442547603414\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(2,4), random_state=1) \n",
    "now1 = time()\n",
    "clf.fit(cl_l_onhot, y_train)\n",
    "print(\"training time: \", time()-now1)\n",
    "print(\"Training accuracy: \", accuracy_score(y_train, clf.predict(cl_l_onhot)))\n",
    "now2 = time()\n",
    "pr = clf.predict(cl_l_test_onhot)\n",
    "print(\"prediction time: \", time()-now2)\n",
    "print(\"Testing accuracy: \", accuracy_score(y_test, pr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from scipy.linalg import pinv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18739724159240723"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srp = SparseRandomProjection(random_state=0, eps=0.3)\n",
    "now = time()\n",
    "transformed_data = srp.fit_transform(X_train)\n",
    "time()-now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0325319766998291"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = time()\n",
    "transformed_data_test = srp.transform(X_test)\n",
    "time()-now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6090, 968)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1523, 968)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  1.0942189693450928\n",
      "Training accuracy:  0.8458128078817734\n",
      "prediction time:  0.0019609928131103516\n",
      "Testing accuracy:  0.7826657912015759\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(2,3), random_state=1) \n",
    "now1 = time()\n",
    "clf.fit(transformed_data, y_train)\n",
    "print(\"training time: \", time()-now1)\n",
    "print(\"Training accuracy: \", accuracy_score(y_train, clf.predict(transformed_data)))\n",
    "now2 = time()\n",
    "pr = clf.predict(transformed_data_test)\n",
    "print(\"prediction time: \", time()-now2)\n",
    "print(\"Testing accuracy: \", accuracy_score(y_test, pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer_1:  2 layer_2:  2  accuracy:  0.5665024630541872\n",
      " layer_1:  2 layer_2:  3  accuracy:  0.7463054187192119\n",
      " layer_1:  2 layer_2:  4  accuracy:  0.7471264367816092\n",
      " layer_1:  2 layer_2:  5  accuracy:  0.7536945812807881\n",
      " layer_1:  3 layer_2:  2  accuracy:  0.7446633825944171\n",
      " layer_1:  3 layer_2:  3  accuracy:  0.7454844006568144\n",
      " layer_1:  3 layer_2:  4  accuracy:  0.7413793103448276\n",
      " layer_1:  3 layer_2:  5  accuracy:  0.7446633825944171\n",
      " layer_1:  4 layer_2:  2  accuracy:  0.7463054187192119\n",
      " layer_1:  4 layer_2:  3  accuracy:  0.7463054187192119\n",
      " layer_1:  4 layer_2:  4  accuracy:  0.7684729064039408\n",
      " layer_1:  4 layer_2:  5  accuracy:  0.7463054187192119\n",
      " layer_1:  5 layer_2:  2  accuracy:  0.5665024630541872\n",
      " layer_1:  5 layer_2:  3  accuracy:  0.5665024630541872\n",
      " layer_1:  5 layer_2:  4  accuracy:  0.7495894909688013\n",
      " layer_1:  5 layer_2:  5  accuracy:  0.7446633825944171\n"
     ]
    }
   ],
   "source": [
    "layer_1 = [2, 3, 4, 5]\n",
    "layer_2 = [2, 3, 4, 5]\n",
    "\n",
    "for i in layer_1:\n",
    "    for j in layer_2:\n",
    "        clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(i, j), random_state=1) \n",
    "        scores = cross_val_score(clf, transformed_data, y_train, cv=5, scoring='accuracy')\n",
    "        print(\" layer_1: \", i, \"layer_2: \", j,  \" accuracy: \", np.median(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  1.0972130298614502\n",
      "Training accuracy:  0.7998357963875206\n",
      "prediction time:  0.0016188621520996094\n",
      "Testing accuracy:  0.7721602101116218\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(4,4), random_state=1) \n",
    "now1 = time()\n",
    "clf.fit(transformed_data, y_train)\n",
    "print(\"training time: \", time()-now1)\n",
    "print(\"Training accuracy: \", accuracy_score(y_train, clf.predict(transformed_data)))\n",
    "now2 = time()\n",
    "pr = clf.predict(transformed_data_test)\n",
    "print(\"prediction time: \", time()-now2)\n",
    "print(\"Testing accuracy: \", accuracy_score(y_test, pr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1-based feature selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.039406776428222656"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(random_state=0, C=1.0).fit(X_train, y_train)\n",
    "now = time()\n",
    "model = SelectFromModel(m, prefit=True)\n",
    "transformed_data = model.transform(X_train)\n",
    "time() - now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009242773056030273"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = time()\n",
    "transformed_data_test = model.transform(X_test)\n",
    "time() - now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  0.022879838943481445\n",
      "Training accuracy:  0.5665024630541872\n",
      "prediction time:  0.0014598369598388672\n",
      "Testing accuracy:  0.5856861457649376\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(2,3), random_state=1) \n",
    "now1 = time()\n",
    "clf.fit(transformed_data, y_train)\n",
    "print(\"training time: \", time()-now1)\n",
    "print(\"Training accuracy: \", accuracy_score(y_train, clf.predict(transformed_data)))\n",
    "now2 = time()\n",
    "pr = clf.predict(transformed_data_test)\n",
    "print(\"prediction time: \", time()-now2)\n",
    "print(\"Testing accuracy: \", accuracy_score(y_test, pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer_1:  2 layer_2:  2  accuracy:  0.5665024630541872\n",
      " layer_1:  2 layer_2:  3  accuracy:  0.5665024630541872\n",
      " layer_1:  2 layer_2:  4  accuracy:  0.7857142857142857\n",
      " layer_1:  2 layer_2:  5  accuracy:  0.7865353037766831\n",
      " layer_1:  3 layer_2:  2  accuracy:  0.7881773399014779\n",
      " layer_1:  3 layer_2:  3  accuracy:  0.7816091954022989\n",
      " layer_1:  3 layer_2:  4  accuracy:  0.7931034482758621\n",
      " layer_1:  3 layer_2:  5  accuracy:  0.7931034482758621\n",
      " layer_1:  4 layer_2:  2  accuracy:  0.7865353037766831\n",
      " layer_1:  4 layer_2:  3  accuracy:  0.5665024630541872\n",
      " layer_1:  4 layer_2:  4  accuracy:  0.7848932676518884\n",
      " layer_1:  4 layer_2:  5  accuracy:  0.7922824302134647\n",
      " layer_1:  5 layer_2:  2  accuracy:  0.7857142857142857\n",
      " layer_1:  5 layer_2:  3  accuracy:  0.7873563218390804\n",
      " layer_1:  5 layer_2:  4  accuracy:  0.7963875205254516\n",
      " layer_1:  5 layer_2:  5  accuracy:  0.7848932676518884\n"
     ]
    }
   ],
   "source": [
    "layer_1 = [2, 3, 4, 5]\n",
    "layer_2 = [2, 3, 4, 5]\n",
    "\n",
    "for i in layer_1:\n",
    "    for j in layer_2:\n",
    "        clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(i, j), random_state=1) \n",
    "        scores = cross_val_score(clf, transformed_data, y_train, cv=5, scoring='accuracy')\n",
    "        print(\" layer_1: \", i, \"layer_2: \", j,  \" accuracy: \", np.median(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  0.5543522834777832\n",
      "Training accuracy:  0.8313628899835797\n",
      "prediction time:  0.0007219314575195312\n",
      "Testing accuracy:  0.7721602101116218\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5,4), random_state=1) \n",
    "now1 = time()\n",
    "clf.fit(transformed_data, y_train)\n",
    "print(\"training time: \", time()-now1)\n",
    "print(\"Training accuracy: \", accuracy_score(y_train, clf.predict(transformed_data)))\n",
    "now2 = time()\n",
    "pr = clf.predict(transformed_data_test)\n",
    "print(\"prediction time: \", time()-now2)\n",
    "print(\"Testing accuracy: \", accuracy_score(y_test, pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
